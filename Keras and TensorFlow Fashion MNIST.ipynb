{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #For plotting\n",
    "from keras.layers import Activation, Dense,Flatten,LeakyReLU\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5.1 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The steps for building the classifier for the fashion MNIST data set is as follows:\n",
    "1) Load the data and standardize the inputs for model traning\n",
    "2) Setup the model with one hidden layers with activation function which is RELU in the first part and leaky ReLU in the second part \n",
    "3) Compile the model with optimizer of choice, loss function and the metrics \n",
    "4) Train the model and calculate the accuracy for the training data\n",
    "5) Predict the values for the test data and calculate the accuracy of the test data\n",
    "\n",
    "ReLU has 87.26% test accuracy and Leaky ReLU has 87% test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.4984 - acc: 0.8260\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3732 - acc: 0.8653\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3334 - acc: 0.8787\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3115 - acc: 0.8851\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2920 - acc: 0.8909\n",
      "10000/10000 [==============================] - 0s 18us/step\n",
      "Test accuracy: 0.8726\n"
     ]
    }
   ],
   "source": [
    "# Relu with linear\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.4976 - acc: 0.8260\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.3724 - acc: 0.8650\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.3343 - acc: 0.8780\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.3085 - acc: 0.8868\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2924 - acc: 0.8920\n",
      "10000/10000 [==============================] - 0s 22us/step\n",
      "Test accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "#Leaky Relu \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.LeakyReLU(alpha=0.01),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5.2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Optimizers in the machine learning are used for tweaking the parameters used in the algorithm. Like any machine learning techniques gradient descent can be used to optimize the parameters. Learning rate is the important that often gets gets tweaked because if the learning rate is too big then control will jump out of the minima and if the learning rate is too small then control might not arrive at the local minima. If optimal learning rate is chosen then model performance will be good. Common gradient descent used is stochastic gradient descent.\n",
    "\n",
    "Some of the other types optimizers used are RMSProp,Adagrad and Adam. Below snippets show the performance of the model with these optimizers using RELU function on the fashion MNIST. Test accuracy for various optimizers is as follows:\n",
    "SGD: 84%\n",
    "RMSProp: 87.37%\n",
    "Adagrad: 86.79%\n",
    "Adam : 87.85%\n",
    "\n",
    "Adam has the best test accuracy of all the optimizers in the current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.7396 - acc: 0.7617\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.5151 - acc: 0.8247\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.4708 - acc: 0.8384\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.4456 - acc: 0.8461\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.4288 - acc: 0.8510\n",
      "10000/10000 [==============================] - 1s 68us/step\n",
      "Test accuracy: 0.8409\n"
     ]
    }
   ],
   "source": [
    "### SGD Optimizer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='SGD', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.5089 - acc: 0.8199\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.3772 - acc: 0.8652\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.3453 - acc: 0.8763\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.3260 - acc: 0.8846\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.3160 - acc: 0.8886\n",
      "10000/10000 [==============================] - 1s 75us/step\n",
      "Test accuracy: 0.8737\n"
     ]
    }
   ],
   "source": [
    "### RMSProp Optimizer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='RMSprop', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.5096 - acc: 0.8244\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.3973 - acc: 0.8625\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.3687 - acc: 0.8716\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.3515 - acc: 0.8765\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.3384 - acc: 0.8799\n",
      "10000/10000 [==============================] - 1s 77us/step\n",
      "Test accuracy: 0.8679\n"
     ]
    }
   ],
   "source": [
    "### Adagrad Optimizer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adagrad', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.4987 - acc: 0.8240\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.3748 - acc: 0.8647\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.3350 - acc: 0.8780\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.3117 - acc: 0.8858\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.2946 - acc: 0.8925\n",
      "10000/10000 [==============================] - 1s 73us/step\n",
      "Test accuracy: 0.8785\n"
     ]
    }
   ],
   "source": [
    "### adam Optimizer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5.3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If the number of hidden units is very few then it will lead to underfitting. We reduced the number of hidden neurons from 120 to 10 and the test accuracy dropped from 87.85% to 84.48%. Increasing the number of hidden layers might possibly lead to overfitting scenario and also increasing the neurons or layers is computationally expensive as the went from 5 seconds to 40 seconds when the hidden nodes is increased to 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.6501 - acc: 0.7814\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.4613 - acc: 0.8397\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.4354 - acc: 0.8484\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.4175 - acc: 0.8543\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.4093 - acc: 0.8572\n",
      "10000/10000 [==============================] - 1s 70us/step\n",
      "Test accuracy: 0.8448\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.4685 - acc: 0.8314\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.3586 - acc: 0.8686\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 14s 238us/step - loss: 0.3206 - acc: 0.8814\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 15s 242us/step - loss: 0.2970 - acc: 0.8902\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 0.2782 - acc: 0.8961\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "Test accuracy: 0.8727\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
